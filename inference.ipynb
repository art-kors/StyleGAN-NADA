{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349f1de8",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73846db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Клонирование репозитория StyleGAN2\n",
    "!git clone https://github.com/rosinality/stylegan2-pytorch.git\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import clip\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google.colab\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# downloads StyleGAN-NADA's weights\n",
    "ids = ['1bhWgbI7oleIBPs9kE7IL7LGkZpzNOsFO', '1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT']\n",
    "for file_id in ids:\n",
    "  downloaded = drive.CreateFile({'id':file_id})\n",
    "  downloaded.FetchMetadata(fetch_all=True)\n",
    "  downloaded.GetContentFile(downloaded.metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33671ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_compare(filtered, clean):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 32))  # Создание подграфиков для визуализации\n",
    "    # Визуализация сгенерированного изображения\n",
    "    axs[1].imshow((filtered.cpu().detach()[0].clip(-1,1).permute(1, 2, 0) + 1) / 2)\n",
    "    axs[1].set_title(\"Обработанное изображение StyleGAN-NADA\")  # Заголовок для сгенерированного изображения\n",
    "    axs[1].axis('off')  # Отключение осей\n",
    "\n",
    "    # Визуализация целевого изображения\n",
    "    axs[0].imshow((clean.cpu().detach()[0].clip(-1,1).permute(1, 2, 0) + 1) / 2)\n",
    "    axs[0].set_title(\"Исходное изображение\")  # Заголовок для исходного изображения\n",
    "    axs[0].axis('off')  # Отключение осей\n",
    "    plt.show()\n",
    "\n",
    "def load_image(img_path, size=1024):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    return transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "def invert_image(target_img, generator, steps=500, lr=0.1, truncation=0.7):\n",
    "    # Инициализация случайного латентного вектора\n",
    "    z = torch.randn(1, 512, device=device)  \n",
    "    w = generator.get_latent(z).detach().clone().requires_grad_(True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam([w], lr=lr)\n",
    "    loss_fn_mse = torch.nn.MSELoss()\n",
    "    loss_fn_vgg = lpips.LPIPS(net=\"vgg\").to(device)  # Perceptual loss\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # Генерация изображения из текущего w\n",
    "        generated_img, _ = generator([w], input_is_latent=True, truncation=truncation)\n",
    "        \n",
    "        # Вычисление потерь (MSE + LPIPS)\n",
    "        loss_mse = loss_fn_mse(generated_img, target_img)\n",
    "        loss_lpips = loss_fn_vgg(generated_img, target_img).mean()\n",
    "        loss = loss_mse + loss_lpips\n",
    "        \n",
    "        # Оптимизация\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return w.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(size=1024, style_dim=latent_dim, n_mlp=8).to(device)\n",
    "state_dict_nada = torch.load('weights.pth', map_location=device)\n",
    "generator.load_state_dict(state_dict_nada['g_ema'])\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a731451",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_clean = Generator(size=1024, style_dim=latent_dim, n_mlp=8).to(device)\n",
    "state_dict_nada = torch.load('stylegan2-ffhq-config-f.pt', map_location=device)\n",
    "generator_clean.load_state_dict(state_dict['g_ema'])\n",
    "generator_clean.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1, 512).to(device)\n",
    "w = generator.get_latent(z)\n",
    "image, _ = generator([w], input_is_latent=True, randomize_noise=False)\n",
    "image_clean, _ = generator_clean([w], input_is_latent=True, randomize_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_compare(image, image_clean)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
